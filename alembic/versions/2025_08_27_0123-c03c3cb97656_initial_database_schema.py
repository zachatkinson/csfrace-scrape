"""Initial database schema

Revision ID: c03c3cb97656
Revises:
Create Date: 2025-08-27 01:23:15.824189

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = "c03c3cb97656"
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "batches",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("name", sa.String(length=255), nullable=False),
        sa.Column("description", sa.Text(), nullable=True),
        sa.Column("status", sa.String(length=20), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.Column("max_concurrent", sa.Integer(), nullable=False),
        sa.Column("continue_on_error", sa.Boolean(), nullable=False),
        sa.Column("output_base_directory", sa.String(length=1024), nullable=False),
        sa.Column("create_archives", sa.Boolean(), nullable=False),
        sa.Column("cleanup_after_archive", sa.Boolean(), nullable=False),
        sa.Column("total_jobs", sa.Integer(), nullable=False),
        sa.Column("completed_jobs", sa.Integer(), nullable=False),
        sa.Column("failed_jobs", sa.Integer(), nullable=False),
        sa.Column("skipped_jobs", sa.Integer(), nullable=False),
        sa.Column("summary_data", sa.JSON(), nullable=True),
        sa.Column("batch_config", sa.JSON(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_batches_status"), "batches", ["status"], unique=False)
    op.create_table(
        "system_metrics",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("timestamp", sa.DateTime(), nullable=False),
        sa.Column("metric_type", sa.String(length=100), nullable=False),
        sa.Column("metric_name", sa.String(length=255), nullable=False),
        sa.Column("numeric_value", sa.Float(), nullable=True),
        sa.Column("string_value", sa.String(length=500), nullable=True),
        sa.Column("json_value", sa.JSON(), nullable=True),
        sa.Column("component", sa.String(length=100), nullable=True),
        sa.Column("environment", sa.String(length=50), nullable=False),
        sa.Column("tags", sa.JSON(), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_system_metrics_component"), "system_metrics", ["component"], unique=False
    )
    op.create_index(
        op.f("ix_system_metrics_metric_type"), "system_metrics", ["metric_type"], unique=False
    )
    op.create_index(
        op.f("ix_system_metrics_timestamp"), "system_metrics", ["timestamp"], unique=False
    )
    op.create_table(
        "scraping_jobs",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("url", sa.String(length=2048), nullable=False),
        sa.Column("domain", sa.String(length=255), nullable=False),
        sa.Column("slug", sa.String(length=255), nullable=True),
        sa.Column("status", sa.String(length=20), nullable=False),
        sa.Column("priority", sa.String(length=10), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.Column("next_retry_at", sa.DateTime(), nullable=True),
        sa.Column("retry_count", sa.Integer(), nullable=False),
        sa.Column("max_retries", sa.Integer(), nullable=False),
        sa.Column("timeout_seconds", sa.Integer(), nullable=False),
        sa.Column("output_directory", sa.String(length=1024), nullable=False),
        sa.Column("custom_slug", sa.String(length=255), nullable=True),
        sa.Column("skip_existing", sa.Boolean(), nullable=False),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("error_type", sa.String(length=255), nullable=True),
        sa.Column("success", sa.Boolean(), nullable=False),
        sa.Column("duration_seconds", sa.Float(), nullable=True),
        sa.Column("content_size_bytes", sa.Integer(), nullable=True),
        sa.Column("images_downloaded", sa.Integer(), nullable=False),
        sa.Column("converter_config", sa.JSON(), nullable=True),
        sa.Column("processing_options", sa.JSON(), nullable=True),
        sa.Column("archive_path", sa.String(length=1024), nullable=True),
        sa.Column("archive_size_bytes", sa.Integer(), nullable=True),
        sa.Column("batch_id", sa.Integer(), nullable=True),
        sa.ForeignKeyConstraint(
            ["batch_id"],
            ["batches.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_scraping_jobs_batch_id"), "scraping_jobs", ["batch_id"], unique=False)
    op.create_index(op.f("ix_scraping_jobs_domain"), "scraping_jobs", ["domain"], unique=False)
    op.create_index(op.f("ix_scraping_jobs_slug"), "scraping_jobs", ["slug"], unique=False)
    op.create_index(op.f("ix_scraping_jobs_status"), "scraping_jobs", ["status"], unique=False)
    op.create_index(op.f("ix_scraping_jobs_url"), "scraping_jobs", ["url"], unique=False)
    op.create_table(
        "content_results",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("job_id", sa.Integer(), nullable=False),
        sa.Column("original_html", sa.Text(), nullable=True),
        sa.Column("converted_html", sa.Text(), nullable=True),
        sa.Column("shopify_html", sa.Text(), nullable=True),
        sa.Column("html_file_path", sa.String(length=1024), nullable=True),
        sa.Column("metadata_file_path", sa.String(length=1024), nullable=True),
        sa.Column("images_directory", sa.String(length=1024), nullable=True),
        sa.Column("title", sa.String(length=500), nullable=True),
        sa.Column("meta_description", sa.Text(), nullable=True),
        sa.Column("published_date", sa.DateTime(), nullable=True),
        sa.Column("author", sa.String(length=255), nullable=True),
        sa.Column("tags", sa.JSON(), nullable=True),
        sa.Column("categories", sa.JSON(), nullable=True),
        sa.Column("og_title", sa.String(length=500), nullable=True),
        sa.Column("og_description", sa.Text(), nullable=True),
        sa.Column("og_image", sa.String(length=1024), nullable=True),
        sa.Column("twitter_card", sa.String(length=50), nullable=True),
        sa.Column("word_count", sa.Integer(), nullable=True),
        sa.Column("image_count", sa.Integer(), nullable=True),
        sa.Column("link_count", sa.Integer(), nullable=True),
        sa.Column("processing_time_seconds", sa.Float(), nullable=True),
        sa.Column("extra_metadata", sa.JSON(), nullable=True),
        sa.Column("conversion_stats", sa.JSON(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["job_id"],
            ["scraping_jobs.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_content_results_job_id"), "content_results", ["job_id"], unique=False)
    op.create_table(
        "job_logs",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("job_id", sa.Integer(), nullable=False),
        sa.Column("level", sa.String(length=10), nullable=False),
        sa.Column("message", sa.Text(), nullable=False),
        sa.Column("timestamp", sa.DateTime(), nullable=False),
        sa.Column("component", sa.String(length=100), nullable=True),
        sa.Column("operation", sa.String(length=100), nullable=True),
        sa.Column("context_data", sa.JSON(), nullable=True),
        sa.Column("exception_type", sa.String(length=255), nullable=True),
        sa.Column("exception_traceback", sa.Text(), nullable=True),
        sa.ForeignKeyConstraint(
            ["job_id"],
            ["scraping_jobs.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_job_logs_job_id"), "job_logs", ["job_id"], unique=False)
    op.create_index(op.f("ix_job_logs_level"), "job_logs", ["level"], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_job_logs_level"), table_name="job_logs")
    op.drop_index(op.f("ix_job_logs_job_id"), table_name="job_logs")
    op.drop_table("job_logs")
    op.drop_index(op.f("ix_content_results_job_id"), table_name="content_results")
    op.drop_table("content_results")
    op.drop_index(op.f("ix_scraping_jobs_url"), table_name="scraping_jobs")
    op.drop_index(op.f("ix_scraping_jobs_status"), table_name="scraping_jobs")
    op.drop_index(op.f("ix_scraping_jobs_slug"), table_name="scraping_jobs")
    op.drop_index(op.f("ix_scraping_jobs_domain"), table_name="scraping_jobs")
    op.drop_index(op.f("ix_scraping_jobs_batch_id"), table_name="scraping_jobs")
    op.drop_table("scraping_jobs")
    op.drop_index(op.f("ix_system_metrics_timestamp"), table_name="system_metrics")
    op.drop_index(op.f("ix_system_metrics_metric_type"), table_name="system_metrics")
    op.drop_index(op.f("ix_system_metrics_component"), table_name="system_metrics")
    op.drop_table("system_metrics")
    op.drop_index(op.f("ix_batches_status"), table_name="batches")
    op.drop_table("batches")
    # ### end Alembic commands ###
